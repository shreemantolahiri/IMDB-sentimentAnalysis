{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreemantolahiri/IMDB-sentimentAnalysis/blob/main/imdb_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfb3b23-1a62-4eb2-85de-0f77400b2fab",
      "metadata": {
        "id": "acfb3b23-1a62-4eb2-85de-0f77400b2fab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7643Mglyfi",
        "outputId": "0e24f7f6-c150-433d-aed6-5ac35b28b7ea"
      },
      "id": "ls7643Mglyfi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27b4badf-e09f-461b-bc5c-b49f445e6e0c",
      "metadata": {
        "id": "27b4badf-e09f-461b-bc5c-b49f445e6e0c"
      },
      "outputs": [],
      "source": [
        "# # read data from text files\n",
        "# with open('datasets/imdb/imdbkaggle/imdb.csv', 'r') as f:\n",
        "#  reviews = f.read()\n",
        "# with open('data/labels.txt', 'r') as f:\n",
        "#  labels = f.read()\n",
        "# print(reviews[:50])\n",
        "# print()\n",
        "# print(labels[:26])\n",
        "path = \"/content/drive/MyDrive/nlp_imdb/data/imdb.csv\"\n",
        "# df_bonus = pd.read_csv(path)\n",
        "spreadsheet = pd.read_csv(path)\n",
        "# reviews = spreadsheet[\"review\"].to_string()\n",
        "reviews = spreadsheet[\"review\"]\n",
        "labels = spreadsheet[\"sentiment\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94387c2-960b-459e-9e60-653ee6cf8889",
      "metadata": {
        "id": "e94387c2-960b-459e-9e60-653ee6cf8889"
      },
      "outputs": [],
      "source": [
        "# for i in reviews:\n",
        "#     print(type(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb00a83-3f4c-4997-88de-c7149de86a35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfb00a83-3f4c-4997-88de-c7149de86a35",
        "outputId": "88564e8c-5b86-46e7-bf98-ea3e6eea8807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      One of the other reviewers has mentioned that ...\n",
            "1      A wonderful little production. <br /><br />The...\n",
            "2      I thought this was a wonderful way to spend ti...\n",
            "3      Basically there's a family where a little boy ...\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...\n",
            "                             ...                        \n",
            "495    \"American Nightmare\" is officially tied, in my...\n",
            "496    First off, I have to say that I loved the book...\n",
            "497    This movie was extremely boring. I only laughe...\n",
            "498    I was disgusted by this movie. No it wasn't be...\n",
            "499    Such a joyous world has been created for us in...\n",
            "Name: review, Length: 500, dtype: object\n",
            "\n",
            "0      positive\n",
            "1      positive\n",
            "2      positive\n",
            "3      negative\n",
            "4      positive\n",
            "         ...   \n",
            "255    negative\n",
            "256    negative\n",
            "257    negative\n",
            "258    positive\n",
            "259    positive\n",
            "Name: sentiment, Length: 260, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(reviews[:500])\n",
        "print()\n",
        "print(labels[:260])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641bbfc8-9ce0-45ab-8418-ae4ab0cd664d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "641bbfc8-9ce0-45ab-8418-ae4ab0cd664d",
        "outputId": "e6a733be-e14e-43be-fe9a-e070edc6120e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.<br /><br />the first thing that struck me abo\n"
          ]
        }
      ],
      "source": [
        "reviews = reviews.str.lower()\n",
        "# reviews= [ data.concat('\\n') for data in reviews]\n",
        "reviews_str = '\\n'.join(reviews)\n",
        "print(reviews_str[0:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b826a305-56a7-43da-b868-72745a950a69",
      "metadata": {
        "id": "b826a305-56a7-43da-b868-72745a950a69"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "all_text = ''.join([c for c in reviews_str if c not in punctuation])\n",
        "\n",
        "# print(reviews[0:400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc7e3fb-ddd0-48af-a53d-a14cfee0ca52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc7e3fb-ddd0-48af-a53d-a14cfee0ca52",
        "outputId": "32853ab2-cbd2-4c37-e02e-e88a9ce1b77f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews : 50000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "reviews_split = all_text.split('\\n')\n",
        "print ('Number of reviews :', len(reviews_split))\n",
        "\n",
        "# print(reviews_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7546a831-fda8-45e2-84f5-319d100755f3",
      "metadata": {
        "id": "7546a831-fda8-45e2-84f5-319d100755f3"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "all_text2 = ' '.join(reviews_split)\n",
        "# create a list of words\n",
        "words = all_text2.split()\n",
        "# Count all the words using Counter Method\n",
        "count_words = Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "# print (count_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c48adee-628e-4434-9aef-a5a4bea2675d",
      "metadata": {
        "id": "4c48adee-628e-4434-9aef-a5a4bea2675d"
      },
      "outputs": [],
      "source": [
        "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "\n",
        "# for i in range(len(reviews_split)):\n",
        "#     reviews_split[i]=reviews_split[i].lstrip(str(i)+\"    \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e85b0cb-1cec-4823-8c53-7dbf85a334be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e85b0cb-1cec-4823-8c53-7dbf85a334be",
        "outputId": "52460c39-8352-4a67-88f3-9ebf6e28b541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28, 4, 1, 77, 1941, 44, 1063, 11, 100, 145, 40, 479, 3324, 393, 461, 26, 3190, 34, 23, 205, 14, 10, 6, 601, 48, 590, 15, 2137, 12, 1, 87, 146, 11, 3255, 69, 42, 3324, 13, 29, 5600, 2, 15378, 134, 4, 582, 61, 282, 7, 205, 35, 1, 670, 138, 1707, 69, 10, 6, 21, 3, 118, 16, 1, 8330, 5794, 39, 11861, 10, 118, 2508, 55, 6064, 15, 5636, 5, 1470, 381, 39, 582, 29, 6, 3407, 7, 1, 352, 340, 4, 1, 23503, 12, 8, 6, 469, 3324, 14, 11, 6, 1, 11516, 338, 5, 1, 16023, 6870, 2543, 1061, 61649, 8, 2637, 1375, 20, 25365, 536, 33, 4727, 2520, 4, 1, 1208, 112, 31, 1, 7153, 25, 2992, 13015, 2, 408, 61650, 37, 17529, 6, 21, 319, 20, 1, 5098, 3720, 536, 6, 344, 5, 81744, 8470, 41120, 15379, 5171, 7893, 2461, 2, 18404, 61651, 329, 9265, 7472, 13445, 2, 8721, 34936, 23, 109, 224, 5436, 12, 9, 57, 128, 1, 269, 1303, 4, 1, 118, 6, 668, 5, 1, 187, 11, 8, 262, 112, 77, 257, 548, 3001, 819, 178, 1271, 4349, 16, 2499, 1096, 819, 1412, 819, 81745, 148, 978, 181, 1, 87, 393, 9, 120, 201, 3255, 69, 14, 37, 1574, 8, 13, 2214, 9, 397, 128, 9, 13, 1550, 16, 8, 18, 14, 9, 278, 51, 9, 1463, 3, 1250, 16, 3324, 2, 183, 10277, 5, 1, 319, 2092, 4, 2100, 582, 21, 40, 582, 18, 7965, 7154, 4974, 14178, 26, 2970, 45, 16, 3, 32611, 7035, 14178, 494, 20, 620, 2, 75, 240, 15, 8, 73, 9934, 753, 816, 7035, 106, 660, 81, 1208, 20591, 668, 5, 63, 549, 4, 931, 1996, 39, 1208, 558, 145, 3324, 22, 196, 411, 3778, 15, 48, 6, 3275, 81746, 43, 22, 68, 75, 7, 1211, 15, 122, 4018, 501], [3, 384, 115, 358, 12, 12, 1, 1365, 3015, 6, 52, 18405, 52, 81747, 1628, 2, 391, 3, 13446, 2, 518, 27652, 280, 4, 1881, 5, 1, 421, 407, 12, 12, 1, 150, 23, 546, 73, 2274, 492, 4607, 21, 60, 44, 183, 31, 1, 81748, 18, 27, 44, 31, 1, 2222, 184, 3295, 99, 22, 68, 349, 64, 1, 13906, 797, 10150, 32, 1, 1794, 5, 1664, 7473, 6746, 21, 60, 6, 8, 73, 266, 1, 145, 18, 8, 6, 3, 41121, 427, 2, 2368, 407, 3, 4350, 358, 42, 28, 4, 1, 79, 3208, 4, 213, 2, 24, 119, 12, 12, 1, 1881, 62, 260, 344, 15, 1, 115, 177, 1, 1069, 4, 1, 2983, 61, 241, 70, 340, 1, 2140, 1024, 3160, 1243, 1149, 90, 5052, 8, 288, 20, 249, 1796, 2, 249, 4608, 567, 15, 1, 134, 3605, 19962, 2, 27653, 2, 1, 713, 567, 4, 63, 1094, 15, 81749, 61652, 29081, 166, 2259, 23, 1900, 73, 223], [9, 194, 10, 13, 3, 384, 98, 5, 1110, 59, 20, 3, 99, 905, 1466, 2484, 1192, 7, 1, 946, 16739, 764, 2, 145, 3, 4019, 213, 1, 114, 6, 4053, 18, 1, 405, 6, 1862, 2, 1, 101, 23, 1473, 54, 1, 73, 6602, 6697, 1540, 498, 133, 46, 196, 26, 694, 50, 34, 929, 10, 6, 21, 1030, 221, 283, 2993, 5197, 9, 194, 8, 13, 3032, 11, 2934, 2033, 6, 125, 1377, 7, 1155, 4, 1, 429, 104, 4, 169, 25, 2327, 5, 6196, 12, 10, 13, 1, 86, 452, 1390, 30, 28, 4, 19963, 1294, 7, 151, 3001, 9, 128, 3, 2101, 133, 195, 109, 74, 1481, 15, 9266, 41122, 7, 10, 58, 1268, 5, 1234, 184, 41, 1237, 1393, 2, 5033, 205, 81, 3, 859, 18, 5099, 182, 11078, 12, 10, 196, 21, 26, 1, 7597, 5216, 4, 24, 642, 18, 8, 13, 32612, 70, 2285, 2877, 25366, 2, 51, 218, 70, 2638, 3, 79, 213, 5, 138, 64, 15, 333]]\n",
            "['one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with mebr br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordbr br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awaybr br i would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side', 'a wonderful little production br br the filming technique is very unassuming very oldtimebbc fashion and gives a comforting and sometimes discomforting sense of realism to the entire piece br br the actors are extremely well chosen michael sheen not only has got all the polari but he has all the voices down pat too you can truly see the seamless editing guided by the references to williams diary entries not only is it well worth the watching but it is a terrificly written and performed piece a masterful production about one of the great masters of comedy and his life br br the realism really comes home with the little things the fantasy of the guard which rather than use the traditional dream techniques remains solid then disappears it plays on our knowledge and our senses particularly with the scenes concerning orton and halliwell and the sets particularly of their flat with halliwells murals decorating every surface are terribly well done', 'i thought this was a wonderful way to spend time on a too hot summer weekend sitting in the air conditioned theater and watching a lighthearted comedy the plot is simplistic but the dialogue is witty and the characters are likable even the well bread suspected serial killer while some may be disappointed when they realize this is not match point 2 risk addiction i thought it was proof that woody allen is still fully in control of the style many of us have grown to lovebr br this was the most id laughed at one of woodys comedies in years dare i say a decade while ive never been impressed with scarlet johanson in this she managed to tone down her sexy image and jumped right into a average but spirited young womanbr br this may not be the crown jewel of his career but it was wittier than devil wears prada and more interesting than superman a great comedy to go see with friends']\n"
          ]
        }
      ],
      "source": [
        "reviews_int = []\n",
        "for review in reviews_split:\n",
        "    r = [vocab_to_int[w] for w in review.split()]\n",
        "    reviews_int.append(r)\n",
        "print(reviews_int[0:3])\n",
        "print(reviews_split[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58afc12d-6ab4-4a22-b2e2-5822f77167a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58afc12d-6ab4-4a22-b2e2-5822f77167a5",
        "outputId": "1b67d0c6-3c37-4d85-f525-c0116b43f740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "[1 1 1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 1 1 1 0 1 0 0 0\n",
            " 0 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1]\n"
          ]
        }
      ],
      "source": [
        "# print(labels[0:100])\n",
        "\n",
        "labels_str = '\\n'.join(labels)\n",
        "\n",
        "# print(type(labels_str))\n",
        "all_labels = ''.join([i for i in labels_str if not i.isdigit()])\n",
        "# all_labels = ''.join([c for c in labels_str if c not in punctuation])\n",
        "labels_split = all_labels.split('\\n')\n",
        "# print(all_labels[0:100])\n",
        "print(len(labels_split))\n",
        "encoded_labels = [1 if label =='positive' else 0 for label in labels_split]\n",
        "encoded_labels = np.array(encoded_labels)\n",
        "\n",
        "print(encoded_labels[0:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129f0d6c-e635-44d9-96ba-b51ed81d750d",
      "metadata": {
        "id": "129f0d6c-e635-44d9-96ba-b51ed81d750d"
      },
      "outputs": [],
      "source": [
        "# print(reviews_int)\n",
        "# print(reviews_len[0:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1d9da6-7204-4475-af26-8a77ab61286e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "ee1d9da6-7204-4475-af26-8a77ab61286e",
        "outputId": "a7cf74ba-01dd-49dc-d6d5-48ec4929168a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    50000.000000\n",
              "mean       230.258240\n",
              "std        170.663887\n",
              "min          4.000000\n",
              "25%        126.000000\n",
              "50%        172.000000\n",
              "75%        280.000000\n",
              "max       2469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "reviews_len = [len(x) for x in reviews_int]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "pd.Series(reviews_len).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccd2158f-fdb0-47f8-b089-3a9b8da6b477",
      "metadata": {
        "id": "ccd2158f-fdb0-47f8-b089-3a9b8da6b477"
      },
      "outputs": [],
      "source": [
        "reviews_int = [ reviews_int[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
        "encoded_labels = [ encoded_labels[i] for i, l in enumerate(reviews_len) if l> 0 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77662dea-a2e2-4e9c-b56f-ee1ab99b6499",
      "metadata": {
        "id": "77662dea-a2e2-4e9c-b56f-ee1ab99b6499"
      },
      "outputs": [],
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features = np.zeros((len(reviews_int), seq_length), dtype = int)\n",
        "\n",
        "    for i, review in enumerate(reviews_int):\n",
        "        review_len = len(review)\n",
        "\n",
        "        if review_len <= seq_length:\n",
        "            zeroes = list(np.zeros(seq_length-review_len))\n",
        "            new = zeroes+review\n",
        "        elif review_len > seq_length:\n",
        "            new = review[0:seq_length]\n",
        "\n",
        "        features[i,:] = np.array(new)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98aa7cc8-0e40-4a2e-88f8-ed59f51f62ba",
      "metadata": {
        "id": "98aa7cc8-0e40-4a2e-88f8-ed59f51f62ba"
      },
      "outputs": [],
      "source": [
        "seq_length = 200\n",
        "features= pad_features(reviews_int,seq_length)\n",
        "len_feat=len(features)\n",
        "encoded_labels=np.array(encoded_labels)\n",
        "split_frac = 0.8\n",
        "train_x = features[0:int(split_frac*len_feat)]\n",
        "train_y = encoded_labels[0:int(split_frac*len_feat)]\n",
        "remaining_x = features[int(split_frac*len_feat):]\n",
        "remaining_y = encoded_labels[int(split_frac*len_feat):]\n",
        "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "test_y = remaining_y[int(len(remaining_y)*0.5):]\n",
        "\n",
        "# print(features[5:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7055656-c3cb-4860-a331-e08651cf6036",
      "metadata": {
        "id": "a7055656-c3cb-4860-a331-e08651cf6036"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5de38fcb-8d32-406a-a7fb-911cb5cedc9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5de38fcb-8d32-406a-a7fb-911cb5cedc9c",
        "outputId": "0e2a5b45-9d22-4444-8d86-aaabd664b1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,    5,  103,    8],\n",
            "        [   9,  278,   10,  ...,   42,    1, 4739],\n",
            "        [   0,    0,    0,  ...,    4,  249,   59],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    8,    3,  298],\n",
            "        [   9, 1173,   10,  ...,   31,   24,  134],\n",
            "        [  16,   46,  281,  ...,  624,    6,    3]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
            "        0, 1])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9979da3c-ca38-406b-a509-945d862f4540",
      "metadata": {
        "id": "9979da3c-ca38-406b-a509-945d862f4540"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model.to('cuda')\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "        self.model.to('cuda')\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        self.model.to('cuda')\n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b22796-2d9c-4f2f-93f4-69a20dc72d9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24b22796-2d9c-4f2f-93f4-69a20dc72d9b",
        "outputId": "0c0bad49-4515-4c1b-9cc2-61bd7da3fda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(181686, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)\n",
        "# SentimentLSTM(\n",
        "#   (embedding): Embedding(74073, 400)\n",
        "#   (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
        "#   (dropout): Dropout(p=0.3)\n",
        "#   (fc): Linear(in_features=256, out_features=1, bias=True)\n",
        "#   (sig): Sigmoid()\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afcade48-d554-43ca-99a6-585f52cbddd1",
      "metadata": {
        "id": "afcade48-d554-43ca-99a6-585f52cbddd1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "train_on_gpu=torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8632af42-e57b-4511-9806-e8546ab92641",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8632af42-e57b-4511-9806-e8546ab92641",
        "outputId": "48a39dd3-34d4-4800-a849-06eeda7d305b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.579951... Val Loss: 0.607850\n",
            "Epoch: 1/4... Step: 200... Loss: 0.565975... Val Loss: 0.563970\n",
            "Epoch: 1/4... Step: 300... Loss: 0.543076... Val Loss: 0.550100\n",
            "Epoch: 1/4... Step: 400... Loss: 0.595614... Val Loss: 0.565069\n",
            "Epoch: 1/4... Step: 500... Loss: 0.683175... Val Loss: 0.679283\n",
            "Epoch: 1/4... Step: 600... Loss: 0.645583... Val Loss: 0.576959\n",
            "Epoch: 1/4... Step: 700... Loss: 0.552534... Val Loss: 0.509791\n",
            "Epoch: 1/4... Step: 800... Loss: 0.461415... Val Loss: 0.432049\n",
            "Epoch: 2/4... Step: 900... Loss: 0.542533... Val Loss: 0.492410\n",
            "Epoch: 2/4... Step: 1000... Loss: 0.379000... Val Loss: 0.431269\n",
            "Epoch: 2/4... Step: 1100... Loss: 0.419411... Val Loss: 0.368928\n",
            "Epoch: 2/4... Step: 1200... Loss: 0.285017... Val Loss: 0.378048\n",
            "Epoch: 2/4... Step: 1300... Loss: 0.353196... Val Loss: 0.360490\n",
            "Epoch: 2/4... Step: 1400... Loss: 0.364834... Val Loss: 0.337387\n",
            "Epoch: 2/4... Step: 1500... Loss: 0.351327... Val Loss: 0.350319\n",
            "Epoch: 2/4... Step: 1600... Loss: 0.391912... Val Loss: 0.327067\n",
            "Epoch: 3/4... Step: 1700... Loss: 0.159950... Val Loss: 0.347411\n",
            "Epoch: 3/4... Step: 1800... Loss: 0.200009... Val Loss: 0.348635\n",
            "Epoch: 3/4... Step: 1900... Loss: 0.194796... Val Loss: 0.332062\n",
            "Epoch: 3/4... Step: 2000... Loss: 0.100639... Val Loss: 0.330624\n",
            "Epoch: 3/4... Step: 2100... Loss: 0.110205... Val Loss: 0.356593\n",
            "Epoch: 3/4... Step: 2200... Loss: 0.343030... Val Loss: 0.340418\n",
            "Epoch: 3/4... Step: 2300... Loss: 0.592615... Val Loss: 0.471546\n",
            "Epoch: 3/4... Step: 2400... Loss: 0.367287... Val Loss: 0.319576\n",
            "Epoch: 4/4... Step: 2500... Loss: 0.112138... Val Loss: 0.382491\n",
            "Epoch: 4/4... Step: 2600... Loss: 0.064228... Val Loss: 0.423064\n",
            "Epoch: 4/4... Step: 2700... Loss: 0.173747... Val Loss: 0.438010\n",
            "Epoch: 4/4... Step: 2800... Loss: 0.060748... Val Loss: 0.364650\n",
            "Epoch: 4/4... Step: 2900... Loss: 0.068727... Val Loss: 0.403005\n",
            "Epoch: 4/4... Step: 3000... Loss: 0.124540... Val Loss: 0.376034\n",
            "Epoch: 4/4... Step: 3100... Loss: 0.142887... Val Loss: 0.382458\n",
            "Epoch: 4/4... Step: 3200... Loss: 0.038786... Val Loss: 0.397047\n"
          ]
        }
      ],
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train().cuda()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    # model = L.from_pretrained(output_dir).to(device)\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        inputs = inputs.type(torch.LongTensor).cuda()\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                inputs = inputs.type(torch.LongTensor).cuda()\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c08f23-ad49-42a3-8204-1cfd9c89ccaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c08f23-ad49-42a3-8204-1cfd9c89ccaf",
        "outputId": "3e39a8be-a0db-48da-8ea0-fb748210e370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.415\n",
            "Test accuracy: 0.863\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    # get predicted outputs\n",
        "    inputs = inputs.type(torch.LongTensor).cuda()\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_review = 'This movie had the worst acting and the dialogue was so bad. I didnt like it.'\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "\n",
        "test_ints = tokenize_review(test_review)\n",
        "print(test_ints)\n",
        "\n",
        "\n",
        "# test sequence padding\n",
        "seq_length=200\n",
        "features = pad_features(test_ints, seq_length)\n",
        "\n",
        "print(features)\n",
        "\n",
        "\n",
        "# test conversion to tensor and pass into your model\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())\n",
        "\n",
        "\n",
        "def predict(net, test_review, sequence_length=200):\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "\n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "\n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())\n",
        "    # printing output value, before rounding\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n",
        "print(test_review)\n",
        "predict(net, test_review, seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvqe4MvpY8Av",
        "outputId": "9597cc75-c456-41c5-a754-cd7ad433093e"
      },
      "id": "wvqe4MvpY8Av",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10, 17, 67, 1, 242, 111, 2, 1, 405, 13, 37, 82, 9, 149, 38, 8]]\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  10  17  67   1 242 111   2   1 405  13  37  82   9 149\n",
            "   38   8]]\n",
            "torch.Size([1, 200])\n",
            "This movie had the worst acting and the dialogue was so bad. I didnt like it.\n",
            "Prediction value, pre-rounding: 0.003106\n",
            "Negative review detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgI1P18aY7wD"
      },
      "id": "AgI1P18aY7wD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}